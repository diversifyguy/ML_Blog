{
  
    
        "post0": {
            "title": "Tabular Modelling NCAA D3 WBB Lineups",
            "content": "What makes a basketball lineup efficient at offense? How much do each of the Four Factors contribute to offensive efficiency? The goal of this exercise is to find out. . About this Dataset . I used @jakeflancer&#39;s bigballR dataset of Division III WBB play-by-play data from the 2019-2020 season aggregated by lineup. This includes &gt;5.8k games in total! . Load &amp; Look at the Data . df = pd.read_csv(&#39;/content/lineups_2020.csv&#39;, error_bad_lines=False, engine=&#39;python&#39;) . df.drop(df[df[&#39;ORTG&#39;] &lt; .5].index, inplace = True) df.drop(df[df[&#39;DRTG&#39;] &lt; .5].index, inplace = True) df.drop(df[df[&#39;oPOSS&#39;] &lt; 20].index, inplace = True) . dep_var = &#39;ORTG&#39; . df[dep_var] = np.log(df[dep_var]) . df.head() . P1 P2 P3 P4 P5 Team Mins oMins dMins oPOSS dPOSS ORTG DRTG NETRTG PTS dPTS FGA dFGA FGM dFGM TPA dTPA TPM dTPM FTA dFTA FTM dFTM RIMA dRIMA RIMM dRIMM ORB dORB DRB dDRB BLK dBLK TO dTO AST dAST ePOSS FG. dFG. TPP dTPP FTP dFTP eFG. deFG. TS. dTS. RIM. dRIM. MID. dMID. TPrate dTPrate RIMrate dRIMrate MIDrate dMIDrate FTrate dFTrate ASTrate dASTrate TOrate dTOrate BLKrate oBLKrate ORB. DRB. TimePerPoss dTimePerPoss . 37 .BETONEY | .COOK | .JONES | .MALUYO | .SIKORA | Evergreen St. | 22.650 | 8.333 | 14.317 | 36 | 38 | ORTG | 84.211 | -11.988 | 26 | 32 | 26 | 30 | 10 | 11 | 13 | 16 | 4 | 5 | 4 | 7 | 2 | 5 | 11 | 7 | 4 | 3 | 3 | 8 | 9 | 16 | 0 | 1 | 9 | 13 | 8 | 9 | 36.0 | 0.385 | 0.367 | 0.308 | 0.312 | 0.500 | 0.714 | 0.462 | 0.450 | 0.466 | 0.480 | 0.364 | 0.429 | 1.000 | 0.429 | 0.500 | 0.533 | 0.423 | 0.233 | 0.077 | 0.233 | 0.154 | 0.233 | 0.800 | 0.818 | 0.250 | 0.342 | 0.0 | 0.038 | 0.158 | 0.529 | 13.889 | 22.605 | . 66 .DIMITRAKOPOULOU | ANNALIESE.SCHREDER | EMMA.GALLAGHER | OLIVIA.PARISI | STELLA.DAVIS | William Smith | 27.383 | 5.750 | 21.633 | 23 | 25 | ORTG | 88.000 | -9.739 | 18 | 22 | 25 | 20 | 6 | 7 | 9 | 4 | 4 | 1 | 2 | 8 | 2 | 7 | 13 | 12 | 2 | 4 | 9 | 4 | 9 | 9 | 0 | 0 | 5 | 3 | 2 | 2 | 22.5 | 0.240 | 0.350 | 0.444 | 0.250 | 1.000 | 0.875 | 0.320 | 0.375 | 0.347 | 0.462 | 0.154 | 0.333 | 0.000 | 0.500 | 0.360 | 0.200 | 0.520 | 0.600 | 0.120 | 0.200 | 0.080 | 0.400 | 0.333 | 0.286 | 0.217 | 0.120 | 0.0 | 0.000 | 0.500 | 0.692 | 15.000 | 51.920 | . 73 .DIMITRAKOPOULOU | ANNALIESE.SCHREDER | LAUREN.DEVANEY | OLIVIA.PARISI | STELLA.DAVIS | William Smith | 27.450 | 7.083 | 20.367 | 23 | 25 | ORTG | 76.000 | 19.652 | 22 | 19 | 23 | 20 | 5 | 7 | 10 | 11 | 2 | 4 | 15 | 2 | 10 | 1 | 8 | 7 | 2 | 2 | 12 | 1 | 12 | 9 | 0 | 2 | 5 | 5 | 5 | 4 | 24.0 | 0.217 | 0.350 | 0.200 | 0.364 | 0.667 | 0.500 | 0.261 | 0.450 | 0.365 | 0.453 | 0.250 | 0.286 | 0.200 | 0.500 | 0.435 | 0.550 | 0.348 | 0.350 | 0.217 | 0.100 | 0.652 | 0.100 | 1.000 | 0.571 | 0.217 | 0.200 | 0.0 | 0.087 | 0.571 | 0.923 | 18.478 | 48.880 | . 114 .GUWBB | CLARISSA.DUEBEL | EMILY.REINNECK | MADELYN.STEPHEN | MEGAN.BARRETT | Greenville | 34.650 | 25.117 | 9.533 | 46 | 46 | ORTG | 80.435 | 10.870 | 42 | 37 | 32 | 36 | 15 | 14 | 9 | 13 | 3 | 2 | 16 | 9 | 9 | 7 | 18 | 13 | 9 | 10 | 5 | 5 | 19 | 15 | 0 | 2 | 6 | 7 | 9 | 6 | 41.5 | 0.469 | 0.389 | 0.333 | 0.154 | 0.562 | 0.778 | 0.516 | 0.417 | 0.530 | 0.459 | 0.500 | 0.769 | 0.600 | 0.200 | 0.281 | 0.361 | 0.562 | 0.361 | 0.156 | 0.278 | 0.500 | 0.250 | 0.600 | 0.429 | 0.130 | 0.152 | 0.0 | 0.062 | 0.250 | 0.792 | 32.761 | 12.435 | . 117 .HFC | BRIANNA.HOLCOMB | MACKENZIE.KOLESARI | MIKAYLA.REIMER | SHARELL.BALL | Holy Fam. Col. (WI) | 19.500 | 10.933 | 8.567 | 37 | 35 | ORTG | 102.857 | -32.587 | 26 | 36 | 30 | 33 | 9 | 15 | 19 | 10 | 4 | 2 | 7 | 5 | 4 | 4 | 0 | 0 | 0 | 0 | 2 | 7 | 11 | 21 | 0 | 0 | 5 | 6 | 5 | 9 | 35.0 | 0.300 | 0.455 | 0.211 | 0.200 | 0.571 | 0.800 | 0.367 | 0.485 | 0.390 | 0.509 | 0.000 | 0.000 | 0.455 | 0.565 | 0.633 | 0.303 | 0.000 | 0.000 | 0.367 | 0.697 | 0.233 | 0.152 | 0.556 | 0.600 | 0.135 | 0.171 | 0.0 | 0.000 | 0.087 | 0.611 | 17.730 | 14.686 | . Using TabularPandas and TabularProc for Decision Trees . The first model we will try is a decision tree. We use fastai&#39;s TabularPandas to split the data into training and validation sets. . procs = [Categorify, FillMissing] . splits = RandomSplitter(valid_pct=0.2)(range_of(df)) . cont,cat = cont_cat_split(df, 1, dep_var=dep_var) . to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits) . len(to.train),len(to.valid) . (3893, 973) . to.show(3) . P1 P2 P3 P4 P5 Team Mins oMins dMins oPOSS dPOSS DRTG NETRTG PTS dPTS FGA dFGA FGM dFGM TPA dTPA TPM dTPM FTA dFTA FTM dFTM RIMA dRIMA RIMM dRIMM ORB dORB DRB dDRB BLK dBLK TO dTO AST dAST ePOSS FG. dFG. TPP dTPP FTP dFTP eFG. deFG. TS. dTS. RIM. dRIM. MID. dMID. TPrate dTPrate RIMrate dRIMrate MIDrate dMIDrate FTrate dFTrate ASTrate dASTrate TOrate dTOrate BLKrate oBLKrate ORB. DRB. TimePerPoss dTimePerPoss ORTG . 21799 ANA.ION | GILLIAN.FLINT | JAMIE.WILCOX | LYNDSEY.MCCOY | MANDY.SKEET | Alfred | 30.132999 | 15.633 | 14.500 | 22 | 19 | 105.263000 | -55.263 | 11 | 20 | 15 | 16 | 4 | 8 | 8 | 2 | 1 | 2 | 2 | 2 | 2 | 2 | 6 | 11 | 3 | 5 | 2 | 1 | 7 | 9 | 0 | 0 | 8 | 3 | 3 | 5 | 20.5 | 0.267 | 0.500 | 0.125 | 1.000 | 1.000 | 1.000 | 0.300 | 0.562 | 0.345 | 0.590 | 0.500 | 0.455 | 0.000 | 0.333 | 0.533 | 0.125 | 0.400 | 0.688 | 0.067 | 0.188 | 0.133 | 0.125 | 0.750 | 0.625 | 0.364 | 0.158 | 0.000 | 0.000 | 0.182 | 0.875 | 42.636002 | 45.789001 | 3.912023 | . 36837 BRILIE.KOVALOFF | COURTNEY.CAROLAN | RILEE.PRICE | SHELBY.HOLMAN | SYDNEY.GRAY | Pacific (OR) | 12.350000 | 6.483 | 5.867 | 23 | 21 | 85.713997 | 31.677 | 27 | 18 | 14 | 12 | 10 | 7 | 3 | 2 | 3 | 1 | 7 | 6 | 4 | 3 | 9 | 7 | 7 | 4 | 1 | 1 | 5 | 4 | 1 | 0 | 7 | 7 | 5 | 2 | 22.0 | 0.714 | 0.583 | 1.000 | 0.500 | 0.571 | 0.500 | 0.821 | 0.625 | 0.779 | 0.606 | 0.778 | 0.571 | 0.000 | 0.667 | 0.214 | 0.167 | 0.643 | 0.583 | 0.143 | 0.250 | 0.500 | 0.500 | 0.500 | 0.286 | 0.304 | 0.333 | 0.083 | 0.000 | 0.200 | 0.833 | 16.913000 | 16.761999 | 4.765510 | . 12298 ALEXYS.MATHANGANI | ALYSSA.OWENS | ELLEN.HAGEN | KIERA.DOWNEY | TAYA.LEE | Rhodes | 18.200001 | 7.133 | 11.067 | 30 | 30 | 63.333000 | 43.333 | 32 | 19 | 26 | 36 | 11 | 8 | 11 | 13 | 3 | 2 | 11 | 3 | 7 | 1 | 8 | 9 | 7 | 3 | 8 | 12 | 18 | 9 | 3 | 1 | 7 | 6 | 5 | 2 | 30.5 | 0.423 | 0.222 | 0.273 | 0.154 | 0.636 | 0.333 | 0.481 | 0.250 | 0.512 | 0.254 | 0.875 | 0.333 | 0.143 | 0.214 | 0.423 | 0.361 | 0.308 | 0.250 | 0.269 | 0.389 | 0.423 | 0.083 | 0.455 | 0.250 | 0.233 | 0.200 | 0.083 | 0.038 | 0.471 | 0.600 | 14.267000 | 22.132999 | 4.669712 | . save_pickle(&#39;to.pkl&#39;,to) . Creating the Decision Tree . xs,y = to.train.xs,to.train.y valid_xs,valid_y = to.valid.xs,to.valid.y . m = DecisionTreeRegressor(max_leaf_nodes=15) m.fit(xs, y); . draw_tree(m, xs, size=15, leaves_parallel=True, precision=1) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Tree 0 TS. ≤ 0.4 mse = 0.1 samples = 3893 value = 4.4 1 TS. ≤ 0.3 mse = 0.1 samples = 923 value = 4.0 0&#45;&gt;1 True 2 TS. ≤ 0.5 mse = 0.0 samples = 2970 value = 4.5 0&#45;&gt;2 False 5 TS. ≤ 0.2 mse = 0.1 samples = 219 value = 3.7 1&#45;&gt;5 6 TOrate ≤ 0.3 mse = 0.0 samples = 704 value = 4.1 1&#45;&gt;6 7 PTS ≤ 3.5 mse = 0.1 samples = 31 value = 3.1 5&#45;&gt;7 8 TOrate ≤ 0.3 mse = 0.0 samples = 188 value = 3.8 5&#45;&gt;8 19 mse = 0.0 samples = 5 value = 2.3 7&#45;&gt;19 20 mse = 0.0 samples = 26 value = 3.2 7&#45;&gt;20 27 mse = 0.0 samples = 119 value = 3.8 8&#45;&gt;27 28 mse = 0.0 samples = 69 value = 3.6 8&#45;&gt;28 13 mse = 0.0 samples = 366 value = 4.2 6&#45;&gt;13 14 ORB. ≤ 0.3 mse = 0.0 samples = 338 value = 4.0 6&#45;&gt;14 25 mse = 0.0 samples = 213 value = 4.0 14&#45;&gt;25 26 mse = 0.0 samples = 125 value = 4.1 14&#45;&gt;26 3 TOrate ≤ 0.3 mse = 0.0 samples = 1598 value = 4.4 2&#45;&gt;3 4 NETRTG ≤ 26.1 mse = 0.0 samples = 1372 value = 4.6 2&#45;&gt;4 9 ORB. ≤ 0.3 mse = 0.0 samples = 1154 value = 4.5 3&#45;&gt;9 10 PTS ≤ 15.5 mse = 0.0 samples = 444 value = 4.3 3&#45;&gt;10 17 mse = 0.0 samples = 566 value = 4.4 9&#45;&gt;17 18 mse = 0.0 samples = 588 value = 4.5 9&#45;&gt;18 23 mse = 0.0 samples = 71 value = 4.1 10&#45;&gt;23 24 mse = 0.0 samples = 373 value = 4.3 10&#45;&gt;24 11 TOrate ≤ 0.3 mse = 0.0 samples = 803 value = 4.6 4&#45;&gt;11 12 TS. ≤ 0.6 mse = 0.0 samples = 569 value = 4.7 4&#45;&gt;12 15 mse = 0.0 samples = 524 value = 4.6 11&#45;&gt;15 16 mse = 0.0 samples = 279 value = 4.5 11&#45;&gt;16 21 mse = 0.0 samples = 349 value = 4.7 12&#45;&gt;21 22 mse = 0.0 samples = 220 value = 4.8 12&#45;&gt;22 Showing the same information using Terence Parr&#39;s dtreeviz library: . samp_idx = np.random.permutation(len(y))[:500] dtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var, fontname=&#39;DejaVu Sans&#39;, scale=1.6, label_fontsize=10, orientation=&#39;LR&#39;) . /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice. out=out, **kwargs) /usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in true_divide ret = ret.dtype.type(ret / rcount) . G node7 node8 leaf19 node7-&gt;leaf19 leaf20 node7-&gt;leaf20 leaf27 node8-&gt;leaf27 leaf28 node8-&gt;leaf28 node5 node5-&gt;node7 node5-&gt;node8 node6 node14 leaf25 node14-&gt;leaf25 leaf26 node14-&gt;leaf26 node6-&gt;node14 leaf13 node6-&gt;leaf13 node1 node1-&gt;node5 node1-&gt;node6 node2 node9 node10 leaf17 node9-&gt;leaf17 leaf18 node9-&gt;leaf18 leaf23 node10-&gt;leaf23 leaf24 node10-&gt;leaf24 node3 node3-&gt;node9 node3-&gt;node10 node4 node11 node12 leaf15 node11-&gt;leaf15 leaf16 node11-&gt;leaf16 leaf21 node12-&gt;leaf21 leaf22 node12-&gt;leaf22 node4-&gt;node11 node4-&gt;node12 node2-&gt;node3 node2-&gt;node4 node0 node0-&gt;node1 &#8804; node0-&gt;node2 &gt; m = DecisionTreeRegressor() m.fit(xs, y); . def r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6) def m_rmse(m, xs, y): return r_mse(m.predict(xs), y) . m_rmse(m, xs, y) . 3e-05 . m_rmse(m, valid_xs, valid_y) . 0.087231 . m.get_n_leaves(), len(xs) . (3449, 3893) . m = DecisionTreeRegressor(min_samples_leaf=25) m.fit(to.train.xs, to.train.y) m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y) . (0.079987, 0.092966) . m.get_n_leaves() . 119 . Analyzing the Data with Random Forests . Next we try using a random forest to analyze the data. . Creating a Random Forest Using sklearn . def rf(xs, y, n_estimators=40, max_samples=1000, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y) . m = rf(xs, y); . m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y) . (0.065957, 0.076898) . preds = np.stack([t.predict(valid_xs) for t in m.estimators_]) . plt.plot([r_mse(preds[:i+1].mean(0), valid_y) for i in range(40)]); . Model Interpretation . What insight can we generate from these models? . Plotting Feature Importance . def rf_feat_importance(m, df): return pd.DataFrame({&#39;cols&#39;:df.columns, &#39;imp&#39;:m.feature_importances_} ).sort_values(&#39;imp&#39;, ascending=False) . fi = rf_feat_importance(m, xs) fi[:10] . cols imp . 50 TS. | 0.406718 | . 48 eFG. | 0.194518 | . 12 NETRTG | 0.092890 | . 42 FG. | 0.076843 | . 13 PTS | 0.061751 | . 66 TOrate | 0.061202 | . 70 ORB. | 0.024174 | . 17 FGM | 0.015895 | . 37 TO | 0.009301 | . 11 DRTG | 0.006674 | . def plot_fi(fi): return fi.plot(&#39;cols&#39;, &#39;imp&#39;, &#39;barh&#39;, figsize=(12,7), legend=False) plot_fi(fi[:30]); . Removing Low-Importance Variables . to_keep = fi[fi.imp&gt;0.005].cols len(to_keep) . 11 . xs_imp = xs[to_keep] valid_xs_imp = valid_xs[to_keep] . m = rf(xs_imp, y) . m_rmse(m, xs_imp, y), m_rmse(m, valid_xs_imp, valid_y) . (0.067258, 0.074519) . plot_fi(rf_feat_importance(m, xs_imp)); . Investigate Feature Redundancy . Are some of our features redundant? . cluster_columns(xs_imp) . def get_oob(df): m = RandomForestRegressor(n_estimators=40, min_samples_leaf=15, max_samples=1000, max_features=0.5, n_jobs=-1, oob_score=True) m.fit(df, y) return m.oob_score_ . get_oob(xs_imp) . 0.909127154372597 . #this improves our OOB score to_drop = [&#39;FG.&#39;, &#39;FGM&#39;, &#39;eFG.&#39;] get_oob(xs_imp.drop(to_drop, axis=1)) . 0.9155733390403249 . xs = xs_imp.drop(to_drop, axis=1) valid_xs = valid_xs_imp.drop(to_drop, axis=1) . save_pickle(&#39;xs.pkl&#39;, xs) save_pickle(&#39;valid_xs.pkl&#39;, valid_xs) . xs = load_pickle(&#39;xs.pkl&#39;) valid_xs = load_pickle(&#39;valid_xs.pkl&#39;) . m = rf(xs, y) m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y) . (0.061264, 0.069554) . Partial Dependence . ax = valid_xs[&#39;TS.&#39;].hist() . #The below plots show how much ORTG changes when TS. and TOrate change, all else equal from sklearn.inspection import plot_partial_dependence fig,ax = plt.subplots(figsize=(12, 4)) plot_partial_dependence(m, valid_xs, [&#39;TS.&#39;,&#39;TOrate&#39;], grid_resolution=20, ax=ax); . Extrapolation and Neural Networks . Can we improve our predictions using a neural network? . df_nn = df df_nn[dep_var] = np.log(df_nn[dep_var]) . cont_nn,cat_nn = cont_cat_split(df_nn, max_card=1000, dep_var=dep_var) . df_nn.head() . P1 P2 P3 P4 P5 Team Mins oMins dMins oPOSS dPOSS ORTG DRTG NETRTG PTS dPTS FGA dFGA FGM dFGM TPA dTPA TPM dTPM FTA dFTA FTM dFTM RIMA dRIMA RIMM dRIMM ORB dORB DRB dDRB BLK dBLK TO dTO AST dAST ePOSS FG. dFG. TPP dTPP FTP dFTP eFG. deFG. TS. dTS. RIM. dRIM. MID. dMID. TPrate dTPrate RIMrate dRIMrate MIDrate dMIDrate FTrate dFTrate ASTrate dASTrate TOrate dTOrate BLKrate oBLKrate ORB. DRB. TimePerPoss dTimePerPoss . 37 .BETONEY | .COOK | .JONES | .MALUYO | .SIKORA | Evergreen St. | 22.650 | 8.333 | 14.317 | 36 | 38 | 1.453893 | 84.211 | -11.988 | 26 | 32 | 26 | 30 | 10 | 11 | 13 | 16 | 4 | 5 | 4 | 7 | 2 | 5 | 11 | 7 | 4 | 3 | 3 | 8 | 9 | 16 | 0 | 1 | 9 | 13 | 8 | 9 | 36.0 | 0.385 | 0.367 | 0.308 | 0.312 | 0.500 | 0.714 | 0.462 | 0.450 | 0.466 | 0.480 | 0.364 | 0.429 | 1.000 | 0.429 | 0.500 | 0.533 | 0.423 | 0.233 | 0.077 | 0.233 | 0.154 | 0.233 | 0.800 | 0.818 | 0.250 | 0.342 | 0.0 | 0.038 | 0.158 | 0.529 | 13.889 | 22.605 | . 66 .DIMITRAKOPOULOU | ANNALIESE.SCHREDER | EMMA.GALLAGHER | OLIVIA.PARISI | STELLA.DAVIS | William Smith | 27.383 | 5.750 | 21.633 | 23 | 25 | 1.472483 | 88.000 | -9.739 | 18 | 22 | 25 | 20 | 6 | 7 | 9 | 4 | 4 | 1 | 2 | 8 | 2 | 7 | 13 | 12 | 2 | 4 | 9 | 4 | 9 | 9 | 0 | 0 | 5 | 3 | 2 | 2 | 22.5 | 0.240 | 0.350 | 0.444 | 0.250 | 1.000 | 0.875 | 0.320 | 0.375 | 0.347 | 0.462 | 0.154 | 0.333 | 0.000 | 0.500 | 0.360 | 0.200 | 0.520 | 0.600 | 0.120 | 0.200 | 0.080 | 0.400 | 0.333 | 0.286 | 0.217 | 0.120 | 0.0 | 0.000 | 0.500 | 0.692 | 15.000 | 51.920 | . 73 .DIMITRAKOPOULOU | ANNALIESE.SCHREDER | LAUREN.DEVANEY | OLIVIA.PARISI | STELLA.DAVIS | William Smith | 27.450 | 7.083 | 20.367 | 23 | 25 | 1.517480 | 76.000 | 19.652 | 22 | 19 | 23 | 20 | 5 | 7 | 10 | 11 | 2 | 4 | 15 | 2 | 10 | 1 | 8 | 7 | 2 | 2 | 12 | 1 | 12 | 9 | 0 | 2 | 5 | 5 | 5 | 4 | 24.0 | 0.217 | 0.350 | 0.200 | 0.364 | 0.667 | 0.500 | 0.261 | 0.450 | 0.365 | 0.453 | 0.250 | 0.286 | 0.200 | 0.500 | 0.435 | 0.550 | 0.348 | 0.350 | 0.217 | 0.100 | 0.652 | 0.100 | 1.000 | 0.571 | 0.217 | 0.200 | 0.0 | 0.087 | 0.571 | 0.923 | 18.478 | 48.880 | . 114 .GUWBB | CLARISSA.DUEBEL | EMILY.REINNECK | MADELYN.STEPHEN | MEGAN.BARRETT | Greenville | 34.650 | 25.117 | 9.533 | 46 | 46 | 1.507227 | 80.435 | 10.870 | 42 | 37 | 32 | 36 | 15 | 14 | 9 | 13 | 3 | 2 | 16 | 9 | 9 | 7 | 18 | 13 | 9 | 10 | 5 | 5 | 19 | 15 | 0 | 2 | 6 | 7 | 9 | 6 | 41.5 | 0.469 | 0.389 | 0.333 | 0.154 | 0.562 | 0.778 | 0.516 | 0.417 | 0.530 | 0.459 | 0.500 | 0.769 | 0.600 | 0.200 | 0.281 | 0.361 | 0.562 | 0.361 | 0.156 | 0.278 | 0.500 | 0.250 | 0.600 | 0.429 | 0.130 | 0.152 | 0.0 | 0.062 | 0.250 | 0.792 | 32.761 | 12.435 | . 117 .HFC | BRIANNA.HOLCOMB | MACKENZIE.KOLESARI | MIKAYLA.REIMER | SHARELL.BALL | Holy Fam. Col. (WI) | 19.500 | 10.933 | 8.567 | 37 | 35 | 1.447471 | 102.857 | -32.587 | 26 | 36 | 30 | 33 | 9 | 15 | 19 | 10 | 4 | 2 | 7 | 5 | 4 | 4 | 0 | 0 | 0 | 0 | 2 | 7 | 11 | 21 | 0 | 0 | 5 | 6 | 5 | 9 | 35.0 | 0.300 | 0.455 | 0.211 | 0.200 | 0.571 | 0.800 | 0.367 | 0.485 | 0.390 | 0.509 | 0.000 | 0.000 | 0.455 | 0.565 | 0.633 | 0.303 | 0.000 | 0.000 | 0.367 | 0.697 | 0.233 | 0.152 | 0.556 | 0.600 | 0.135 | 0.171 | 0.0 | 0.000 | 0.087 | 0.611 | 17.730 | 14.686 | . df_nn[cat_nn].nunique() . P1 1288 P2 1586 P3 1696 P4 1621 P5 1287 ... dBLK 33 TO 108 dTO 118 AST 99 dAST 90 Length: 36, dtype: int64 . cat_nn.remove(&#39;P1&#39;) cat_nn.remove(&#39;P2&#39;) cat_nn.remove(&#39;P3&#39;) cat_nn.remove(&#39;P4&#39;) cat_nn.remove(&#39;P5&#39;) cat_nn.remove(&#39;Team&#39;) . procs_nn = [Categorify, FillMissing, Normalize] to_nn = TabularPandas(df_nn, procs_nn, cat_nn, cont_nn, splits=splits, y_names=dep_var) . dls = to_nn.dataloaders(1024) . y = to_nn.train.y y.min(),y.max() . (0.7005710601806641, 1.6402279138565063) . learn = tabular_learner(dls, y_range=(.65,1.7), layers=[500,250], n_out=1, loss_func=F.mse_loss) . learn.lr_find() . SuggestedLRs(valley=tensor(0.0021)) . learn.fit_one_cycle(20, 0.0021) . epoch train_loss valid_loss time . 0 | 0.001234 | 0.001878 | 00:00 | . 1 | 0.001147 | 0.002336 | 00:00 | . 2 | 0.001278 | 0.001875 | 00:00 | . 3 | 0.001241 | 0.001721 | 00:00 | . 4 | 0.001183 | 0.002145 | 00:00 | . 5 | 0.001102 | 0.001863 | 00:00 | . 6 | 0.001078 | 0.001740 | 00:00 | . 7 | 0.001134 | 0.002154 | 00:00 | . 8 | 0.001176 | 0.002288 | 00:00 | . 9 | 0.001153 | 0.001643 | 00:00 | . 10 | 0.001114 | 0.001292 | 00:00 | . 11 | 0.001056 | 0.001282 | 00:00 | . 12 | 0.001014 | 0.001316 | 00:00 | . 13 | 0.000950 | 0.001159 | 00:00 | . 14 | 0.000912 | 0.001075 | 00:00 | . 15 | 0.000870 | 0.001114 | 00:00 | . 16 | 0.000828 | 0.001068 | 00:00 | . 17 | 0.000786 | 0.001068 | 00:00 | . 18 | 0.000747 | 0.001064 | 00:00 | . 19 | 0.000718 | 0.001058 | 00:00 | . preds,targs = learn.get_preds() r_mse(preds,targs) . 0.032522 . learn.save(&#39;nn&#39;) . Path(&#39;models/nn.pth&#39;) . Conclusion . We began with a dataset that looked at &gt;5.8k games from the 2019-2020 DIII NCAA WBB season aggregated by lineup. Our goal was to investigate what variables would predict ORTG. . As we may have anticipated, TS. was by far the best predictor of ORTG, followed by eFG. and FG.. . After that, NETRTG and PTS were the best predictors, which tells us that the best lineups in general, i.e. those with a good net rating and those which were on the floor long enough to score a lot of PTS, tended to have better ORTGs. . Finally TOrate was also an important factor, followed by ORB.. This goes to show that taking care of the ball tends to be even more important than crashing the glass in contributing to ORTG. . After more and more refinement, our models became extremely accurate in predicting ORTG, with our neural network ultimately having the best predictive power. How this might be used in helping coaches determine which lineups to play or which tactics to emphasize is still to-be-determined. There is likely more insight into ORTG that could be unlocked using machine learning. .",
            "url": "https://www.jjhoffstein.com/2021/07/07/NCAA-D3-WBB-Lineup-Analysis.html",
            "relUrl": "/2021/07/07/NCAA-D3-WBB-Lineup-Analysis.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Woj Twitter Analysis",
            "content": "Woj Bombs - Twitter Analysis using NLP . Anyone who seriously follows the NBA knows where to go for breaking news: the Twitter accounts of ESPN&#39;s Adrian Wojnarowski. . Like any Twitter account, it&#39;s easy to forget that Woj&#39;s account grew from humble beginnings. . Here&#39;s Woj&#39;s first ever tweet from @wojespn (note: Woj&#39;s Twitter handle changed when he joined ESPN in 2009), dated 24-June-2009: This is your new spot for Adrian Wojnarowski and Johnny Ludden&#39;s breaking NBA news on Yahoo! Sports. . &mdash; Adrian Wojnarowski (@wojespn) June 24, 2009 Since then, Woj&#39;s follower count has grown to 4.7 million as of 6-July-2021. . What might we learn by analyzing 12 years of Woj tweets? The purpose of this exercise is to find out. . Visualizing the Tweets . After using twint to extract all the tweets from Woj&#39;s account, I went about cleaning the data and organizing it into a pandas dataframe: . df = pd.read_csv(&#39;/Users/jhoffstein/twint/woj.csv&#39;, sep=&#39; t&#39;, lineterminator=&#39; r&#39;, low_memory=False) . display(df.info()) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 16539 entries, 0 to 16538 Data columns (total 36 columns): # Column Non-Null Count Dtype -- -- 0 id 16539 non-null object 1 conversation_id 16538 non-null float64 2 created_at 16538 non-null object 3 date 16538 non-null object 4 time 16538 non-null object 5 timezone 16538 non-null float64 6 user_id 16538 non-null float64 7 username 16538 non-null object 8 name 16538 non-null object 9 place 0 non-null float64 10 tweet 16538 non-null object 11 language 16538 non-null object 12 mentions 16538 non-null object 13 urls 16538 non-null object 14 photos 16538 non-null object 15 replies_count 16538 non-null float64 16 retweets_count 16538 non-null float64 17 likes_count 16538 non-null float64 18 hashtags 16538 non-null object 19 cashtags 16538 non-null object 20 link 16538 non-null object 21 retweet 16538 non-null object 22 quote_url 1408 non-null object 23 video 16538 non-null float64 24 thumbnail 353 non-null object 25 near 0 non-null float64 26 geo 0 non-null float64 27 source 0 non-null float64 28 user_rt_id 0 non-null float64 29 user_rt 0 non-null float64 30 retweet_id 0 non-null float64 31 reply_to 16538 non-null object 32 retweet_date 0 non-null float64 33 translate 0 non-null float64 34 trans_src 0 non-null float64 35 trans_dest 0 non-null float64 dtypes: float64(18), object(18) memory usage: 4.5+ MB . None . drop_list = [&#39;place&#39;,&#39;near&#39;,&#39;geo&#39;,&#39;source&#39;,&#39;user_rt_id&#39;,&#39;user_rt&#39;,&#39;retweet_id&#39;,&#39;retweet_date&#39;,&#39;translate&#39;,&#39;trans_src&#39;,&#39;trans_dest&#39;] df = df.drop(columns=drop_list) . df[&#39;tweet&#39;] = df[&#39;tweet&#39;].str.replace(&#39;http S+|www. S+&#39;, &#39;&#39;,case=False) . /var/folders/dr/jwj01j9s64s4s24j87qpmg8sq27k40/T/ipykernel_24930/411855716.py:2: FutureWarning: The default value of regex will change from True to False in a future version. . Basic Data Visualization with Texthero and Sweetviz . from texthero import preprocessing # create a custom pipeline to preprocess the raw text custom_pipeline = [preprocessing.fillna , preprocessing.lowercase , preprocessing.remove_digits , preprocessing.remove_punctuation , preprocessing.remove_diacritics , preprocessing.remove_stopwords] # call clean() method to clean the raw text in &#39;tweet&#39; col and pass the custom_pipeline to pipeline argument df[&#39;clean_tweet&#39;] = hero.clean(df[&#39;tweet&#39;], pipeline = custom_pipeline) . df[&#39;pca&#39;] = ( df[&#39;clean_tweet&#39;] .pipe(hero.clean) .pipe(hero.tfidf) .pipe(hero.pca) ) . df[&#39;tfidf&#39;] = ( hero.tfidf(df[&#39;clean_tweet&#39;], max_features=100) ) df[[&quot;tfidf&quot;]].head(2) . df[&#39;named_entities&#39;] = hero.named_entities(df[&#39;clean_tweet&#39;]) . NUM_TOP_WORDS = 10 hero.top_words(df[&#39;clean_tweet&#39;])[:NUM_TOP_WORDS] . sources 5741 league 3791 espn 3437 tell 3096 deal 2741 nba 2425 source 2107 tells 1924 yahoo 1791 sports 1667 Name: clean_tweet, dtype: int64 . hero.top_words(df[&#39;clean_tweet&#39;]).head(20).plot.bar(figsize=(15,10)) plt.show() . from texthero import stopwords default_stopwords = stopwords.DEFAULT #add a list of stopwords to the stopwords stop_w = [&quot;co&quot;,&quot;https&quot;,&quot;http&quot;, &quot;tell&quot;, &quot;tells&quot;, &quot;game&quot;, &quot;season&quot;, &quot;sports&quot;, &quot;two&quot;] custom_stopwords = default_stopwords.union(set(stop_w)) #Call remove_stopwords and pass the custom_stopwords list df[&#39;clean_tweet&#39;] = hero.remove_stopwords(df[&#39;clean_tweet&#39;], custom_stopwords) . hero.top_words(df[&#39;clean_tweet&#39;]).head(20).plot.bar(figsize=(15,10)) plt.show() . hero.visualization.wordcloud(df[&#39;clean_tweet&#39;],width = 400, height= 400,background_color=&#39;White&#39;) . df[&#39;kmeans&#39;] = ( df[&#39;clean_tweet&#39;] .pipe(hero.tfidf,max_features=300) .pipe(hero.kmeans, n_clusters=5) ) . /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:786: FutureWarning: &#39;precompute_distances&#39; was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:792: FutureWarning: &#39;n_jobs&#39; was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). . id conversation_id created_at date time timezone user_id username name tweet language mentions urls photos replies_count retweets_count likes_count hashtags cashtags link retweet quote_url video thumbnail reply_to clean_tweet pca tfidf named_entities kmeans . 0 n1412479849080320001 | 1.412480e+18 | 2021-07-06 14:33:33 EDT | 2021-07-06 | 14:33:33 | -400.0 | 50323173.0 | wojespn | Adrian Wojnarowski | Reporting with @Malika_Andrews: Milwaukee’s Giannis Antetokounmpo has continued around-the-clock treatment on his left knee with hopes of becoming cleared to play Game 1 of the Finals vs. Phoenix tonight. There’s expected to be a game-time decision on his availability. | en | [{&#39;screen_name&#39;: &#39;malika_andrews&#39;, &#39;name&#39;: &#39;malika andrews&#39;, &#39;id&#39;: &#39;2379200053&#39;}] | [] | [] | 244.0 | 1059.0 | 7308.0 | [] | [] | https://twitter.com/wojespn/status/1412479849080320001 | False | NaN | 0.0 | NaN | [] | reporting malika andrews milwaukee&#39; giannis antetokounmpo continued around clock treatment left knee hopes becoming cleared play finals vs phoenix tonight &#39; expected time decision availability | [-0.181686791381161, 0.01917158240664424] | [0.3432569527357847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3432569527357847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62827486342842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35486837971815144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3418394685694084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3561379446022077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [(milwaukee, GPE, 28, 37), (phoenix, GPE, 159, 166), (tonight, TIME, 167, 174)] | 0 | . 1 n1412114670060773377 | 1.412114e+18 | 2021-07-05 14:22:27 EDT | 2021-07-05 | 14:22:27 | -400.0 | 50323173.0 | wojespn | Adrian Wojnarowski | Mosley and Unseld Jr., are also serious head coaching candidates for the Orlando Magic job, sources tell ESPN. | en | [] | [] | [] | 29.0 | 173.0 | 1340.0 | [] | [] | https://twitter.com/wojespn/status/1412114670060773377 | False | NaN | 0.0 | NaN | [] | mosley unseld jr also serious head coaching candidates orlando magic job sources espn | [0.06612464056400236, -0.2739120161846545] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43770103298202834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25478465375369536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4664468983737951, 0.0, 0.0, 0.452008393763466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46026997785353085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20241832150279795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262291173144681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0... | [(mosley, ORG, 0, 6), (orlando, GPE, 60, 67)] | 4 | . 2 n1412114367852781568 | 1.412114e+18 | 2021-07-05 14:21:15 EDT | 2021-07-05 | 14:21:15 | -400.0 | 50323173.0 | wojespn | Adrian Wojnarowski | Washington’s search process for a new coach has narrowed to several assistants, including Dallas’ Jamahl Mosley, Milwaukee’s Darvin Ham and Charles Lee and Denver’s Wes Unseld, Jr., sources tell ESPN. Those are among the candidates who will talk to Wizards again this week. | en | [] | [] | [] | 164.0 | 543.0 | 4098.0 | [] | [] | https://twitter.com/wojespn/status/1412114367852781568 | False | NaN | 0.0 | NaN | [] | washington&#39; search process new coach narrowed several assistants including dallas&#39; jamahl mosley milwaukee&#39; darvin ham charles lee denver&#39; wes unseld jr sources espn among candidates talk wizards week | [0.14222517760420586, -0.37900182601770677] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5531525166012126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38487942444586554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5435096396056114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30577448810009067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39621882350397053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [(washington, GPE, 0, 10), (dallas, GPE, 80, 86), (jamahl mosley, PERSON, 88, 101), (milwaukee, GPE, 103, 112), (darvin ham, PERSON, 114, 124), (charles lee, PERSON, 126, 137), (denver, GPE, 139, 145)] | 4 | . 3 n1412097959219675144 | 1.412097e+18 | 2021-07-05 13:16:03 EDT | 2021-07-05 | 13:16:03 | -400.0 | 50323173.0 | wojespn | Adrian Wojnarowski | Schlenk announced the agreement on a media conference call minutes ago. | en | [] | [] | [] | 20.0 | 91.0 | 1633.0 | [] | [] | https://twitter.com/wojespn/status/1412097959219675144 | False | NaN | 0.0 | NaN | [] | schlenk announced agreement media conference call minutes ago | [-0.05094735889135986, 0.011885021709133971] | [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [(schlenk, ORG, 0, 7)] | 0 | . 4 n1412097377725566977 | 1.412097e+18 | 2021-07-05 13:13:45 EDT | 2021-07-05 | 13:13:45 | -400.0 | 50323173.0 | wojespn | Adrian Wojnarowski | Atlanta president/GM Travis Schlenk told reporters that an agreement was in place to shed interim label after McMillan led Hawks to Eastern Conference Finals. | en | [] | [] | [] | 29.0 | 187.0 | 2762.0 | [] | [] | https://twitter.com/wojespn/status/1412097377725566977 | False | NaN | 0.0 | NaN | [] | atlanta president gm travis schlenk told reporters agreement place shed interim label mcmillan led hawks eastern conference finals | [-0.08607428153598168, -0.012672414297085188] | [0.0, 0.0, 0.0, 0.5672489225848258, 0.0, 0.0, 0.6296566841281105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5308117556715819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [(atlanta, GPE, 0, 7), (gm, ORG, 18, 20), (travis schlenk, PERSON, 21, 35), (mcmillan, PERSON, 92, 100)] | 0 | . hero.scatterplot(df, &#39;pca&#39;, color = &#39;kmeans&#39;, hover_data=[&#39;clean_tweet&#39;] ) . Analyze engagement over time . plt.figure(figsize=(17,10)) sns.lineplot(data=df[&#39;retweets_count&#39;], dashes=False) plt.title(&quot;Retweets over time&quot;) plt.show() . plt.figure(figsize=(17,10)) sns.lineplot(data=df[&#39;replies_count&#39;], dashes=False) plt.title(&quot;Replies over time&quot;) plt.show() . plt.figure(figsize=(17,10)) sns.lineplot(data=df[&#39;likes_count&#39;], dashes=False) plt.title(&quot;Likes over time&quot;) plt.show() . View Common Phrases . import re # Gensim import gensim from gensim.utils import simple_preprocess # NLTK import nltk from nltk.corpus import stopwords from collections import Counter from wordcloud import WordCloud import warnings warnings.filterwarnings(&quot;ignore&quot;, category=DeprecationWarning) . def tokenize(tweet): for word in tweet: yield(gensim.utils.simple_preprocess(str(word), deacc=True)) df[&#39;clean_tweet_tokens&#39;] = list(tokenize(df[&#39;clean_tweet&#39;])) . stop_words = stopwords.words(&#39;english&#39;) stop_words.extend([&quot;co&quot;,&quot;https&quot;,&quot;http&quot;, &quot;tell&quot;, &quot;tells&quot;, &quot;game&quot;, &quot;season&quot;, &quot;sports&quot;, &quot;two&quot;]) # REMOVE STOPWORDS def remove_stopwords(tweets): return [[word for word in simple_preprocess(str(tweet)) if word not in stop_words] for tweet in tweets] df[&#39;tokens_no_stop&#39;] = remove_stopwords(df[&#39;clean_tweet_tokens&#39;]) . df[&#39;length&#39;] = df[&#39;tokens_no_stop&#39;].apply(len) df = df.drop(df[df[&#39;length&#39;]&lt;3].index) df = df.drop([&#39;length&#39;], axis=1) df.shape df.reset_index(drop=True, inplace=True) . df.to_pickle(&#39;pre-processed.pkl&#39;) . def sent_to_words(sentences): for sentence in sentences: yield(gensim.utils.simple_preprocess(str(sentence), deacc=True)) # deacc=True removes punctuations data_words = list(sent_to_words(df[&#39;clean_tweet&#39;])) . bigram = gensim.models.Phrases(data_words, min_count=10, threshold=100) trigram = gensim.models.Phrases(bigram[data_words], threshold=100) # Faster way to get a sentence clubbed as a bigram bigram_mod = gensim.models.phrases.Phraser(bigram) trigram_mod = gensim.models.phrases.Phraser(trigram) def make_bigrams(texts): return [bigram_mod[doc] for doc in texts] def make_trigrams(texts): return [trigram_mod[bigram_mod[doc]] for doc in texts] # Form Bigrams data_words_bigrams = make_bigrams(data_words) . terms_bigram = [list(bigrams(tweet)) for tweet in df[&#39;tokens_no_stop&#39;]] # View bigrams for the first tweet terms_bigram[0] . [(&#39;reporting&#39;, &#39;malika&#39;), (&#39;malika&#39;, &#39;andrews&#39;), (&#39;andrews&#39;, &#39;milwaukee&#39;), (&#39;milwaukee&#39;, &#39;giannis&#39;), (&#39;giannis&#39;, &#39;antetokounmpo&#39;), (&#39;antetokounmpo&#39;, &#39;continued&#39;), (&#39;continued&#39;, &#39;around&#39;), (&#39;around&#39;, &#39;clock&#39;), (&#39;clock&#39;, &#39;treatment&#39;), (&#39;treatment&#39;, &#39;left&#39;), (&#39;left&#39;, &#39;knee&#39;), (&#39;knee&#39;, &#39;hopes&#39;), (&#39;hopes&#39;, &#39;becoming&#39;), (&#39;becoming&#39;, &#39;cleared&#39;), (&#39;cleared&#39;, &#39;play&#39;), (&#39;play&#39;, &#39;finals&#39;), (&#39;finals&#39;, &#39;vs&#39;), (&#39;vs&#39;, &#39;phoenix&#39;), (&#39;phoenix&#39;, &#39;tonight&#39;), (&#39;tonight&#39;, &#39;expected&#39;), (&#39;expected&#39;, &#39;time&#39;), (&#39;time&#39;, &#39;decision&#39;), (&#39;decision&#39;, &#39;availability&#39;)] . bigrams = list(itertools.chain(*terms_bigram)) # Create counter of words in clean bigrams bigram_counts = collections.Counter(bigrams) . bigram_df = pd.DataFrame(bigram_counts.most_common(25), columns=[&#39;bigram&#39;, &#39;count&#39;]) . d = bigram_df.set_index(&#39;bigram&#39;).T.to_dict(&#39;records&#39;) # Create network plot G = nx.Graph() # Create connections between nodes for k, v in d[0].items(): G.add_edge(k[0], k[1], weight=(v * 5)) fig, ax = plt.subplots(figsize=(11, 9)) pos = nx.spring_layout(G, k=2) # Plot networks nx.draw_networkx(G, pos, font_size=10, width=3, edge_color=&#39;grey&#39;, node_color=&#39;purple&#39;, with_labels = False, ax=ax) # Create offset labels for key, value in pos.items(): x, y = value[0]+.135, value[1]+.065 ax.text(x, y, s=key, bbox=dict(facecolor=&#39;red&#39;, alpha=0.15), horizontalalignment=&#39;center&#39;, fontsize=14) plt.show() . Conclusion . Woj generally plays things pretty close to the vest. The words and phrases he uses tend to be pretty programmatic, and he rarely strays from his typical tweet structures. . Journalists like Woj need to be very reliable and structured with how the break news. The popularity of Woj&#39;s Twitter account over time are a testament to this predictable, disciplined approach. .",
            "url": "https://www.jjhoffstein.com/twint/data_visualization/2021/07/05/Woj-Twitter-Analysis.html",
            "relUrl": "/twint/data_visualization/2021/07/05/Woj-Twitter-Analysis.html",
            "date": " • Jul 5, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "My First ML Application",
            "content": ". My First ML Application . I created my first application! It asks users to upload a picture of Michael Jordan, LeBron James, or Kobe Bryant, and tells you who you uploaded. Here is the link: https://mybinder.org/v2/gh/diversifyguy/goat_app/HEAD?urlpath=%2Fvoila%2Frender%2Fbball_player_classifier.ipynb . Unfortunately, it doesn&#39;t really work, and I&#39;m not sure why! My suspicion is that it&#39;s due to overfitting, which is something I&#39;ll learn about more later. . For now, I&#39;ll call this good enough and move on. Onward! .",
            "url": "https://www.jjhoffstein.com/2021/06/23/My-First-ML-Application.html",
            "relUrl": "/2021/06/23/My-First-ML-Application.html",
            "date": " • Jun 23, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Beginning",
            "content": ". Beginning . This is my first blog post. I&#39;ve become interested in data science, machine learning, and artificial intelligence, and now here I am blogging about it. My hope is that blogging will help clarify my thoughts, sharpen my ideas, and elicit feedback from others. Thank you for your participation in this process! . As a blogger, my goal is to heed Professor James Miller&#39;s three pieces of writing advice: be clear, be concise, and be interesting -- in that order of importance. . Mine: Be clear, be concise, be interesting -- in that order of importance. . &mdash; James Miller (@JimDMiller) March 29, 2021 . Please wish me luck on this journey, and feel free to DM me anytime on Twitter @jjhoffstein. Thank you!! . What Classes Am I Taking? . My plan is two take two classes: Stanford&#39;s CSS 229, taught by Andrew Ng; and fast.ai&#39;s Practical Deep Learning for Coders, taught by Jeremy Howard. The former is more of a theory course, the latter is more of a practical course. . If you&#39;re interested in learning more about Andrew Ng and his mission, I recommend this video: . . If you&#39;re interested in Jeremy Howard and his mission, I recommend this video: . . Without Further Ado . Let&#39;s get started! .",
            "url": "https://www.jjhoffstein.com/2021/06/22/Beginning.html",
            "relUrl": "/2021/06/22/Beginning.html",
            "date": " • Jun 22, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Bio . 2020+: Joined Vassar Women’s Basketball as full-time assistant coach. 2018 - 2020: Earned Master’s Degree in Exercise and Sports Studies from Smith College. Graduate-assistant coach for Smith Women’s Basketball; made it to the NCAA Tournament 2nd Round year 1 and to the Sweet 16 year 2 before tournament was cut short due to COVID-19. 2014 - 2018: Worked as a finance associate at Goldman Sachs in New York City. Focused on liquidity risk management and asset-liability management in Corporate Treasury Department. 2010 - 2014: Earned Bachelor of Arts in Economics from Amherst College. Student-assistant coach for Amherst Women’s Basketball; made it to the NCAA Tournament Sweet 16. . Misc . I love using YouTube as a learning tool and believe it is the biggest human revolution since the Gutenberg printing press. I similarly love using Twitter as a learning tool. I try and avoid politics &amp; pop culture and just focus on content that will level-up my knowledge and skills. I’ve collated my basketball coaching portfolio and published it at jjhoffstein.github.io I have a photic sneeze reflex, which means that I sneeze basically every time I walk outside and look at the sun. .",
          "url": "https://www.jjhoffstein.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.jjhoffstein.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}